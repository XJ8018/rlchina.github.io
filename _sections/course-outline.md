--- 
title: 课程大纲 
icon: fa-th 
order: 4 
--- 
<p style="text-align:justify; text-justify:inter-ideograph;color: black">
1、卢宗青: Value-based Reinforcement Learning <br />
<a href="https://www.ntu.edu.sg/home/boan/" target="_blank">课件链接</a>
- Introduction to Reinforcement Learning <br />
    &emsp; - About RL <br />
    &emsp; - RL problem <br />
    &emsp; - Inside an RL agent <br />
    &emsp; - Markov Decision Processes <br />
- Value-based Methods <br />
    &emsp; - Dynamic Programming <br />
    &emsp; - Monte Carlo <br />
    &emsp; - TD Learning <br />
    &emsp; - Off-policy Learning <br />
    &emsp; - DQN and its variants <br />
<br />
2、汪军: Policy-based RL and RL Theory <br />
- Policy based approaches <br />
    &emsp; - Policy gradient theorem <br />
    &emsp; - REINFORCE algorithm <br />
    &emsp; - Natural policy gradient <br />
- PAC Learning theory <br />
    &emsp; - Definition and concepts <br />
    &emsp; - Concentration inequalities <br />
    &emsp; - Uniform convergence <br />
- RL theory <br />
    &emsp; - Approximate Dynamic Programming <br />
    &emsp; - Approximate Value Iteractions <br />
    &emsp; - Approximate Policy Iterations <br />
    &emsp; - Theoretical bounds and sample complexity analysis <br />
<br />
3、Haitham: Optimisation in Learning <br />
- Motivation, Functions & Solution Types <br />
    &emsp; - Applications of optimisation in Machine Learning <br />
    &emsp; - Convex vs Non-Convex Optimisation Techniques <br />
    &emsp; - Non-Convex Optimisation Solution Types <br />
- Brief Survey of Optimisation Methods – Merits & Demerits <br />
    &emsp; - Zero-Order Techniques <br />
    &emsp; - First-Order Techniques <br />
    &emsp; - Second-Order Techniques <br />
- ADAM: An Adaptive Solver <br />
    &emsp; - Brief History of ADAM <br />
    &emsp; - ADAM’s Description <br />
- ADAM’s Convergence Proof: <br />
    &emsp; - Proof Strategy <br />
    &emsp; - Assumptions <br />
    &emsp; - Loss Function Difference Bound and Stationary Point Convergence <br />
<br />
4、张伟楠: Model-based Reinforcement Learning <br />
- Model-based RL concepts <br />
    &emsp; - Blackbox & whitebox models <br />
- Classic MBRL <br />
    &emsp; - Q-planning <br />
    &emsp; - Dyna-Q <br />
- Blackbox MBRL <br />
    &emsp; - Model Predictive Control <br />
    &emsp; - Probabilistic Ensemble & Trajectory Sampling <br />
    &emsp; - Stochastic Lower Bound Optimization <br />
    &emsp; - Model-based Policy Optimization <br />
    &emsp; - Bidirectional Model based Policy Optimization <br />
- Whitebox MBRL <br />
    &emsp; - Stochastic Value Gradient <br />
    &emsp; - Model Augmented Actor Critic <br />
<br />
5、朱占星: Control as Inference  <br />
- Basics of probabilistic graphical models (D-separation, variational inference.) <br />
- Connection between reinforcement learning and probabilistic inference.  <br />
- Soft Q-learning  <br />
- Entropy-regularized policy gradient <br />
<br />
6、俞扬: Imitation Learning  <br />
- Preliminary <br />
- Supervised Learning & Behavior Cloning <br />
- Generative Adversarial Learning & GAIL <br />
- Advanced Topics <br />
- From Imitating Policies to Imitating Environments <br />
<br />
7、郝建业: Hierarchical Reinforcement Learning <br />
- Long-episode and sparse-reward RL tasks <br />
- Hierarchical RL Concepts <br />
- Option Framework <br />
- Feudal Network & Variants <br />
- Goal-oriented RL <br />
<br />
8、张海峰: Game Theory Basics  <br />
- Motivation and Normal-form Game <br />
- NE Concepts and Existence Proof <br />
- Repeated Game and Tit-for-tat <br />
- Extensive-form Game and Subgame Perfect Equilibrium  <br />
- Other Solution Concepts <br />
<br />
9、安波: Multi-agent Systems  <br />
- History and Current Status <br />
- Multi-agent Coordination and Negotiation <br />
- Multi-agent Planning and Teamwork <br />
- Distributed Constraint Optimization <br />
- Multi-agent Organizational Design <br />
- Game Theory and Mechanism Design <br />
- Game Theory for Security <br />
<br />
10、张崇洁: Deep Multi-agent Learning <br />
- Multi-Agent MDP and Dec-POMDP <br />
- Centralized Training and Decentralized Execution and Individual-Global Maximization Principle <br />
- Value-Based Deep MARL Methods <br />
- Multi-Agent Policy Gradient Methods <br />
- Theoretical Analysis  <br />
<br />
11、杨耀东: Advances in Multi-agent Learning <br />
- Extensive-form games and its basics <br />
- Ficiticious play <br />
- Generalised weakened Ficiticious play <br />
- Policy Space Response Oracle (PSRO) <br />
- Alpha-Rank <br />
- PSRO-Nash <br />
- PSRO-Rechtified Nash <br />
- PSRO-AlphaRank <br />
<br />
12、徐任远: Mean-field Games and Controls <br />
- Mean-field game models  <br />
    &emsp; - Examples  <br />
    &emsp; - Approximation of non-cooperative games in the large population regime  <br />
    &emsp; - Equilibrium concept  <br />
- Existence and uniqueness of the equilibrium  <br />
- Q-learning based algorithm  <br />
    &emsp; - Stabilizing and smoothing techniques  <br />
    &emsp; - Convergence and sample complexity analysis  <br />
- General algorithms for learning mean-fifield games  <br />
    &emsp; - Value-based algorithms (light touch)  <br />
    &emsp; - Policy-based algorithms (light touch) <br />
- Mean-field control models   <br />
    &emsp; - Examples  <br />
    &emsp; - Approximation of cooperative games in the large population regime  <br />
    &emsp; - Social optimality condition  <br />
- Dynamic programming principle on the probability measure space  <br />
- Q-learning based algorithm  <br />
    &emsp; - Kernel regression  <br />
    &emsp; - Approximated Bellman update  <br />
    &emsp; - Convergence and sample complexity analysis <br />
</p>
